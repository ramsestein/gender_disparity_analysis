# Gender Disparity Analysis Pipeline

**AnÃ¡lisis automatizado de disparidad de gÃ©nero en conferencias y congresos**

Este software procesa grabaciones de video de conferencias, congresos y eventos acadÃ©micos para analizar automÃ¡ticamente la participaciÃ³n por gÃ©nero, generando mÃ©tricas sobre tiempo de habla, interrupciones y dinÃ¡micas conversacionales.

## ğŸ“œ Licencia

Este proyecto se distribuye bajo **Licencia MIT** (ver archivo [LICENSE](LICENSE)).

El cÃ³digo se libera pÃºblicamente para permitir:
- âœ… AuditorÃ­as independientes de metodologÃ­as
- âœ… Reproducibilidad de estudios
- âœ… Mejora continua por la comunidad
- âœ… Acceso democrÃ¡tico a herramientas de anÃ¡lisis de gÃ©nero

## ğŸ“‹ CaracterÃ­sticas

- **ExtracciÃ³n de audio** de archivos de video
- **NormalizaciÃ³n** de niveles de audio
- **DiarizaciÃ³n** de speakers (quiÃ©n habla cuÃ¡ndo)
- **TranscripciÃ³n** con Whisper (speech-to-text)
- **ClasificaciÃ³n de gÃ©nero** con enfoque hÃ­brido (pitch + modelo pre-entrenado)
- **AnÃ¡lisis de sentimiento y emociones** con modelos BERT
- **Ãndices de poder y conflictividad** calculados automÃ¡ticamente
- **Reportes acadÃ©micos detallados** en Markdown

## ğŸ“š DocumentaciÃ³n Detallada de InvestigaciÃ³n

Para una comprensiÃ³n profunda de la metodologÃ­a y los hallazgos, consulta los siguientes documentos:

- ğŸ”¬ [**MetodologÃ­a Completa**](final_reports/resultados/METHOD.md): Detalle tÃ©cnico del pipeline y marco estadÃ­stico (11 secciones).
- ğŸ“Š [**Resultados del Estudio**](final_reports/resultados/SUMMARY_RESULTS.md): SÃ­ntesis de hallazgos y tablas comparativas.
- ğŸ“– [**Diccionario de Variables**](final_reports/resultados/DICCIONARIO_VARIABLES.md): Definiciones operacionales de todas las mÃ©tricas (12 secciones + glosario).
- ğŸ“‰ [**Informe EstadÃ­stico Extenso**](final_reports/resultados/INFORME_STAT.md): 50 secciones con anÃ¡lisis inferencial, clusters y efectos mixtos.

## ğŸš€ InstalaciÃ³n RÃ¡pida

### Requisitos Previos
- **Python 3.8 o superior** instalado en tu sistema
  - Windows: Descarga desde [python.org](https://www.python.org/downloads/)
  - Mac: `brew install python3` o descarga desde python.org
  - Linux: `sudo apt-get install python3 python3-venv python3-pip`

### InstalaciÃ³n AutomÃ¡tica

1. **Descarga o clona este proyecto**

2. **Coloca tus videos** en la carpeta `video/` dentro del proyecto. Debes crearla y llamarla asÃ­ en el proyecto

3. **Ejecuta el script de instalaciÃ³n y pipeline:**

**Windows:**
```bash
run_pipeline.bat
```

**Linux/Mac:**
```bash
chmod +x run_pipeline.sh
./run_pipeline.sh
```

El script automÃ¡ticamente:
- âœ… Crea el entorno virtual de Python
- âœ… Instala todas las dependencias necesarias
- âœ… Te pedirÃ¡ tu token de Hugging Face (te guiarÃ¡ en cÃ³mo obtenerlo)
- âœ… Ejecuta todo el pipeline completo

**Â¡Eso es todo!** El script te guiarÃ¡ paso a paso.

## ğŸ“ Estructura del Proyecto

```
gender_diaparity/
â”œâ”€â”€ video/                      # Videos de entrada
â”œâ”€â”€ fuentes/                    # Carpetas de trabajo (generadas automÃ¡ticamente)
â”‚   â”œâ”€â”€ audio/                  # Audio extraÃ­do
â”‚   â”œâ”€â”€ audio_normalized/       # Audio normalizado
â”‚   â”œâ”€â”€ diarization/           # Segmentos de speakers
â”‚   â”œâ”€â”€ transcription/         # Transcripciones
â”‚   â””â”€â”€ gender_classification/ # ClasificaciÃ³n de gÃ©nero
â”œâ”€â”€ final_reports/             # Reportes finales
â”‚   â”œâ”€â”€ csv/                   # Reportes en CSV
â”‚   â”œâ”€â”€ excel/                 # Reportes en Excel
â”‚   â””â”€â”€ resultados/            # DocumentaciÃ³n del estudio
â”‚       â”œâ”€â”€ METHOD.md          # MetodologÃ­a completa
â”‚       â”œâ”€â”€ SUMMARY_RESULTS.md # SÃ­ntesis de resultados
â”‚       â”œâ”€â”€ INFORME_STAT.md    # Informe estadÃ­stico (50 secciones)
â”‚       â”œâ”€â”€ DICCIONARIO_VARIABLES.md # Diccionario de variables y glosario
â”‚       â”œâ”€â”€ csv/               # 82 CSVs de respaldo estadÃ­stico
â”‚       â””â”€â”€ graficos/          # Visualizaciones (25 grÃ¡ficos + 15 de clustering)
â”œâ”€â”€ logs/                      # Logs de procesamiento
â”œâ”€â”€ src/                       # Scripts del pipeline de audio
â”‚   â”œâ”€â”€ 01_video_to_audio.py
â”‚   â”œâ”€â”€ 02_normalize_audio.py
â”‚   â”œâ”€â”€ 03_diarization.py
â”‚   â”œâ”€â”€ 04_transcription.py
â”‚   â”œâ”€â”€ 05_gender_classification.py
â”‚   â””â”€â”€ 06_final_report.py
â”œâ”€â”€ src_stat/                  # Scripts de anÃ¡lisis estadÃ­stico
â”‚   â”œâ”€â”€ c01_build_user_dataset.py  # ConstrucciÃ³n del dataset a nivel usuario
â”‚   â””â”€â”€ c02_cluster_analysis.py    # Clustering no supervisado y efecto llamada
â”œâ”€â”€ run_pipeline.bat           # Ejecutar pipeline (Windows)
â”œâ”€â”€ run_pipeline.sh            # Ejecutar pipeline (Linux/Mac)
â”œâ”€â”€ requirements.txt           # Dependencias
â””â”€â”€ README.md                  # Este archivo
```

## ğŸ¯ Uso

### OpciÃ³n 1: Ejecutar Pipeline Completo (Recomendado)

**Windows:**
```bash
run_pipeline.bat
```

**Linux/Mac:**
```bash
chmod +x run_pipeline.sh
./run_pipeline.sh
```

### OpciÃ³n 2: Ejecutar Scripts Individuales

```bash
# 1. Extraer audio de videos
python src/01_video_to_audio.py

# 2. Normalizar audio
python src/02_normalize_audio.py

# 3. DiarizaciÃ³n de speakers
python src/03_diarization.py

# 4. TranscripciÃ³n
python src/04_transcription.py

# 5. ClasificaciÃ³n de gÃ©nero
python src/05_gender_classification.py

# 6. Generar reportes finales
python src/06_final_report.py
```

## ğŸ“Š Formato del Reporte Final

Los reportes incluyen las siguientes columnas:

| Columna | DescripciÃ³n |
|---------|-------------|
| `intervention_id` | ID Ãºnico de la intervenciÃ³n |
| `start_time` | Tiempo de inicio (segundos) |
| `end_time` | Tiempo de fin (segundos) |
| `duration` | DuraciÃ³n de la intervenciÃ³n (segundos) |
| `speaker` | ID del speaker (SPEAKER_00, SPEAKER_01, etc.) |
| `gender` | GÃ©nero clasificado (male/female) |
| `gender_confidence` | Confianza de la clasificaciÃ³n (0-1) |
| `text` | TranscripciÃ³n del texto |
| `has_overlap` | Si hay overlap con otro speaker |
| `overlap_duration` | DuraciÃ³n del overlap (segundos) |
| `interrupts_previous` | Si interrumpe al speaker anterior |
| `interrupted_by_next` | Si es interrumpido por el siguiente |
| `turn_number` | NÃºmero de turno en la conversaciÃ³n |
| `sentiment` | Tono afectivo (Positive/Negative/Neutral) |
| `emotion` | CategorÃ­a emocional (joy, anger, etc.) |
| `conflict_score` | Grado de conflictividad del turno |
| `assertiveness_score` | Nivel de asertividad directa |

## ğŸ§ª MetodologÃ­a del Estudio

El anÃ¡lisis se basa en un marco multidimensional de **11 pilares** que evalÃºan desde la acÃºstica hasta la segmentaciÃ³n de roles:

1.  **Ingesta y NormalizaciÃ³n:** AplicaciÃ³n del estÃ¡ndar EBU R128 (-23 LUFS).
2.  **DiarizaciÃ³n Avanzada:** Uso de Pyannote 3.1 con embeddings ECAPA-TDNN.
3.  **Doble ValidaciÃ³n de GÃ©nero:** Cruce de anÃ¡lisis de Pitch (F0) y modelos Transformer (Wav2Vec2).
4.  **TranscripciÃ³n Alineada:** OpenAI Whisper large-v2 segmentado por orador.
5.  **AnÃ¡lisis Gramatical:** DetecciÃ³n de imperativos y diversidad lÃ©xica (TTR) vÃ­a spaCy.
6.  **AnÃ¡lisis PragmÃ¡tico:** DetecciÃ³n de *hedges*, acuerdos, desacuerdos y cortesÃ­a.
7.  **AnÃ¡lisis Afectivo:** Sentimiento y emociones mediante modelos BERT.
8.  **DinÃ¡micas de Poder:** Ãndices de conflictividad, asertividad y eco lÃ©xico.
9.  **Interacciones:** AnÃ¡lisis de transiciÃ³n de turnos, interrupciones y apropiaciÃ³n de ideas.
10. **Modelado EstadÃ­stico:** Modelos de efectos mixtos y correcciÃ³n FDR.
11. **Clustering No Supervisado:** SegmentaciÃ³n de roles (K-Means, DBSCAN, JerÃ¡rquico), cruce cluster Ã— gÃ©nero y efecto llamada.

## ğŸ“ˆ Resultados Principales

El estudio realizado sobre **12,138 intervenciones** de **652 participantes** en **75 sesiones** revela:

### A nivel de intervenciÃ³n
- ğŸ¤ **SegregaciÃ³n Discursiva:** Fuerte tendencia a transiciones intra-gÃ©nero (85% Hâ†’H; 75% Mâ†’M).
- ğŸ—£ï¸ **DuraciÃ³n:** Las mujeres presentan intervenciones ligeramente mÃ¡s largas (+1.18s) y mayor expresiÃ³n de desacuerdo.
- ğŸ“‰ **TamaÃ±os del Efecto:** Aunque significativos, la mayorÃ­a de los efectos son de magnitud despreciable (|g| < 0.08), sugiriendo paridad en el estilo comunicativo bajo condiciones de debate estructurado.
- âš–ï¸ **Equidad:** Un 15% de las sesiones alcanzan niveles de paridad funcional superiores al 0.85.

### A nivel de usuario (Clustering)
- ğŸ”¬ **SegmentaciÃ³n de roles:** K-Means identifica 2 perfiles: Moderadores (57.5%) y Audiencia (42.5%), sin sesgo de gÃ©nero en la asignaciÃ³n (p=0.17).
- ğŸ” **AmplificaciÃ³n de brechas:** Dentro de cada rol, ciertas diferencias de gÃ©nero se amplifican. Los hombres moderadores acaparan 19% mÃ¡s intervenciones (+10% general). Los hombres audiencia hacen 48% mÃ¡s preguntas (+12% general).
- ğŸ§² **Efecto Llamada de GÃ©nero:** La composiciÃ³n de gÃ©nero de los moderadores predice la de la audiencia (Ï=0.361, p=0.004). Charlas con moderadoras mayoritariamente femeninas atraen **51.6%** de audiencia femenina vs **27.2%** con moderadores masculinos (OR=3.16).

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Cambiar modelo de Whisper

En `src/04_transcription.py`, lÃ­nea ~443:
```python
model_size="base"  # Opciones: tiny, base, small, medium, large
```

- `tiny`: MÃ¡s rÃ¡pido, menor precisiÃ³n
- `base`: Balance (por defecto)
- `small`: Buena precisiÃ³n
- `medium`: Alta precisiÃ³n
- `large`: MÃ¡xima precisiÃ³n, mÃ¡s lento

### Desactivar reducciÃ³n de ruido

En `src/02_normalize_audio.py`, lÃ­nea ~273:
```python
apply_noise_reduction=False  # Cambiar a False
```

## ğŸ“ˆ Rendimiento

Tiempos aproximados por audio de 20 minutos (CPU):

| Script | Tiempo |
|--------|--------|
| 01 - ExtracciÃ³n | ~2 min |
| 02 - NormalizaciÃ³n | ~50s |
| 03 - DiarizaciÃ³n | ~20 min |
| 04 - TranscripciÃ³n | ~30s |
| 05 - GÃ©nero | ~2 min |
| 06 - Reportes | 1s |
| **Total** | **~25 min** |

**Nota sobre Memoria:** El script de diarizaciÃ³n (`03_diarization.py`) incluye optimizaciÃ³n automÃ¡tica de RAM y monitoreo en tiempo real. Libera recursos despuÃ©s de cada audio para evitar saturaciÃ³n.

## ğŸ“ MÃ©todos de ClasificaciÃ³n de GÃ©nero

El sistema usa un **enfoque hÃ­brido**:

1. **AnÃ¡lisis de Pitch (F0)**
   - RÃ¡pido, baseline
   - Male: < 165 Hz
   - Female: â‰¥ 165 Hz

2. **Modelo Pre-entrenado (Wav2Vec2)**
   - Mayor precisiÃ³n (~95%+)
   - DecisiÃ³n final

**LÃ³gica de decisiÃ³n:**
- Si ambos coinciden â†’ Alta confianza
- Si difieren â†’ Usar modelo (mÃ¡s preciso)

## ğŸ› SoluciÃ³n de Problemas

### Error: "HF_TOKEN not found"
- Verifica que el archivo `.env` existe en la raÃ­z
- Verifica que contiene `HF_TOKEN=tu_token`

### Error: "No module named 'pyannote'"
```bash
pip install -r requirements.txt
```

### Error: "GPU not available"
- El pipeline funciona en CPU por defecto
- No es necesario GPU

## ğŸ“ Licencia

Este proyecto es para uso acadÃ©mico/investigaciÃ³n.

## ğŸ‘¥ Contribuciones

Para reportar bugs o sugerir mejoras, contacta al equipo de desarrollo.

## ğŸ“– CÃ³mo Citar Este Proyecto

Si utilizas este software en tu investigaciÃ³n o publicaciÃ³n acadÃ©mica, por favor cÃ­talo de la siguiente manera:

### Formato APA (7Âª ediciÃ³n)
```
[Autor/es]. (2026). Gender Disparity Analysis Pipeline (VersiÃ³n 1.0) [Software]. 
GitHub. https://github.com/ramsestein/gender_disparity_analysis
```

### Formato BibTeX
```bibtex
@software{gender_disparity_pipeline_2026,
  author = {RamsÃ©s Marrero Garcia},
  title = {Gender Disparity Analysis Pipeline: Automated Gender Disparity Analysis in Academic Conferences},
  year = {2026},
  publisher = {GitHub},
  url = {https://github.com/ramsestein/gender_disparity_analysis},
  version = {1.0}
}
```

## ğŸ“š Referencias BibliogrÃ¡ficas

Este proyecto utiliza las siguientes herramientas y bibliotecas de cÃ³digo abierto:

### Herramientas Principales

**Pyannote Audio - DiarizaciÃ³n de Speakers**
```
Bredin, H., & Laurent, A. (2021). End-to-end speaker segmentation for overlap-aware 
resegmentation. In Proc. Interspeech 2021 (pp. 3111-3115).
DOI: 10.21437/Interspeech.2021-560
```
```bibtex
@inproceedings{Bredin2021,
  author = {HervÃ© Bredin and Antoine Laurent},
  title = {{End-to-end speaker segmentation for overlap-aware resegmentation}},
  booktitle = {Proc. Interspeech 2021},
  year = {2021},
  pages = {3111--3115},
  doi = {10.21437/Interspeech.2021-560}
}
```

**OpenAI Whisper - TranscripciÃ³n AutomÃ¡tica**
```
Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., & Sutskever, I. (2022). 
Robust speech recognition via large-scale weak supervision. arXiv preprint arXiv:2212.04356.
```
```bibtex
@article{radford2022whisper,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2212.04356},
  year={2022}
}
```

**Mozilla Common Voice - ClasificaciÃ³n de GÃ©nero**
```
Ardila, R., Branson, M., Davis, K., Henretty, M., Kohler, M., Meyer, J., ... & Weber, G. (2020). 
Common Voice: A massively-multilingual speech corpus. In Proceedings of the 12th Language 
Resources and Evaluation Conference (pp. 4218-4222).
```
```bibtex
@inproceedings{ardila2020common,
  title={Common Voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  booktitle={Proceedings of the 12th Language Resources and Evaluation Conference},
  pages={4218--4222},
  year={2020}
}
```

**Modelo Pre-entrenado:** `alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech`
```
Modelo basado en Wav2Vec2-XLSR-53 fine-tuneado para clasificaciÃ³n de gÃ©nero.
Disponible en: https://huggingface.co/alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech
```

### Bibliotecas de Procesamiento de Audio

**librosa - AnÃ¡lisis de Audio**
```
McFee, B., Raffel, C., Liang, D., Ellis, D. P., McVicar, M., Battenberg, E., & Nieto, O. (2015). 
librosa: Audio and music signal analysis in python. In Proceedings of the 14th Python in Science 
Conference (Vol. 8, pp. 18-25).
```
```bibtex
@inproceedings{mcfee2015librosa,
  title={librosa: Audio and music signal analysis in python},
  author={McFee, Brian and Raffel, Colin and Liang, Dawen and Ellis, Daniel PW and McVicar, Matt and Battenberg, Eric and Nieto, Oriol},
  booktitle={Proceedings of the 14th python in science conference},
  volume={8},
  pages={18--25},
  year={2015}
}
```

