# Gender Disparity Analysis Pipeline

**AnÃ¡lisis automatizado de disparidad de gÃ©nero en conferencias y congresos**

Este software procesa grabaciones de video de conferencias, congresos y eventos acadÃ©micos para analizar automÃ¡ticamente la participaciÃ³n por gÃ©nero, generando mÃ©tricas sobre tiempo de habla, interrupciones y dinÃ¡micas conversacionales.

## ğŸ“œ Licencia

Este proyecto se distribuye bajo **Licencia MIT** (ver archivo [LICENSE](LICENSE)).

El cÃ³digo se libera pÃºblicamente para permitir:
- âœ… AuditorÃ­as independientes de metodologÃ­as
- âœ… Reproducibilidad de estudios
- âœ… Mejora continua por la comunidad
- âœ… Acceso democrÃ¡tico a herramientas de anÃ¡lisis de gÃ©nero

## ğŸ“‹ CaracterÃ­sticas

- **ExtracciÃ³n de audio** de archivos de video
- **NormalizaciÃ³n** de niveles de audio
- **DiarizaciÃ³n** de speakers (quiÃ©n habla cuÃ¡ndo)
- **TranscripciÃ³n** con Whisper (speech-to-text)
- **ClasificaciÃ³n de gÃ©nero** con enfoque hÃ­brido (pitch + modelo pre-entrenado)
- **Reportes completos** en CSV y Excel con anÃ¡lisis de overlaps e interrupciones

## ğŸš€ InstalaciÃ³n RÃ¡pida (Para Usuarios Sin Experiencia)

### Requisitos Previos
- **Python 3.8 o superior** instalado en tu sistema
  - Windows: Descarga desde [python.org](https://www.python.org/downloads/)
  - Mac: `brew install python3` o descarga desde python.org
  - Linux: `sudo apt-get install python3 python3-venv python3-pip`

### InstalaciÃ³n AutomÃ¡tica

1. **Descarga o clona este proyecto**

2. **Coloca tus videos** en la carpeta `video/` dentro del proyecto. Debes crearla y llamarla asÃ­ en el proyecto

3. **Ejecuta el script de instalaciÃ³n y pipeline:**

**Windows:**
```bash
run_pipeline.bat
```

**Linux/Mac:**
```bash
chmod +x run_pipeline.sh
./run_pipeline.sh
```

El script automÃ¡ticamente:
- âœ… Crea el entorno virtual de Python
- âœ… Instala todas las dependencias necesarias
- âœ… Te pedirÃ¡ tu token de Hugging Face (te guiarÃ¡ en cÃ³mo obtenerlo)
- âœ… Ejecuta todo el pipeline completo

**Â¡Eso es todo!** El script te guiarÃ¡ paso a paso.

## ğŸ“ Estructura del Proyecto

```
gender_diaparity/
â”œâ”€â”€ video/                      # Videos de entrada
â”œâ”€â”€ fuentes/                    # Carpetas de trabajo (generadas automÃ¡ticamente)
â”‚   â”œâ”€â”€ audio/                  # Audio extraÃ­do
â”‚   â”œâ”€â”€ audio_normalized/       # Audio normalizado
â”‚   â”œâ”€â”€ diarization/           # Segmentos de speakers
â”‚   â”œâ”€â”€ transcription/         # Transcripciones
â”‚   â””â”€â”€ gender_classification/ # ClasificaciÃ³n de gÃ©nero
â”œâ”€â”€ final_reports/             # Reportes finales
â”‚   â”œâ”€â”€ csv/                   # Reportes en CSV
â”‚   â””â”€â”€ excel/                 # Reportes en Excel
â”œâ”€â”€ logs/                      # Logs de procesamiento
â”œâ”€â”€ src/                       # Scripts del pipeline
â”‚   â”œâ”€â”€ 01_video_to_audio.py
â”‚   â”œâ”€â”€ 02_normalize_audio.py
â”‚   â”œâ”€â”€ 03_diarization.py
â”‚   â”œâ”€â”€ 04_transcription.py
â”‚   â”œâ”€â”€ 05_gender_classification.py
â”‚   â””â”€â”€ 06_final_report.py
â”œâ”€â”€ run_pipeline.bat           # Ejecutar pipeline (Windows)
â”œâ”€â”€ run_pipeline.sh            # Ejecutar pipeline (Linux/Mac)
â”œâ”€â”€ requirements.txt           # Dependencias
â””â”€â”€ README.md                  # Este archivo
```

## ğŸ¯ Uso

### OpciÃ³n 1: Ejecutar Pipeline Completo (Recomendado)

**Windows:**
```bash
run_pipeline.bat
```

**Linux/Mac:**
```bash
chmod +x run_pipeline.sh
./run_pipeline.sh
```

### OpciÃ³n 2: Ejecutar Scripts Individuales

```bash
# 1. Extraer audio de videos
python src/01_video_to_audio.py

# 2. Normalizar audio
python src/02_normalize_audio.py

# 3. DiarizaciÃ³n de speakers
python src/03_diarization.py

# 4. TranscripciÃ³n
python src/04_transcription.py

# 5. ClasificaciÃ³n de gÃ©nero
python src/05_gender_classification.py

# 6. Generar reportes finales
python src/06_final_report.py
```

## ğŸ“Š Formato del Reporte Final

Los reportes incluyen las siguientes columnas:

| Columna | DescripciÃ³n |
|---------|-------------|
| `intervention_id` | ID Ãºnico de la intervenciÃ³n |
| `start_time` | Tiempo de inicio (segundos) |
| `end_time` | Tiempo de fin (segundos) |
| `duration` | DuraciÃ³n de la intervenciÃ³n (segundos) |
| `speaker` | ID del speaker (SPEAKER_00, SPEAKER_01, etc.) |
| `gender` | GÃ©nero clasificado (male/female) |
| `gender_confidence` | Confianza de la clasificaciÃ³n (0-1) |
| `text` | TranscripciÃ³n del texto |
| `has_overlap` | Si hay overlap con otro speaker |
| `overlap_duration` | DuraciÃ³n del overlap (segundos) |
| `interrupts_previous` | Si interrumpe al speaker anterior |
| `interrupted_by_next` | Si es interrumpido por el siguiente |
| `turn_number` | NÃºmero de turno en la conversaciÃ³n |

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Cambiar modelo de Whisper

En `src/04_transcription.py`, lÃ­nea ~443:
```python
model_size="base"  # Opciones: tiny, base, small, medium, large
```

- `tiny`: MÃ¡s rÃ¡pido, menor precisiÃ³n
- `base`: Balance (por defecto)
- `small`: Buena precisiÃ³n
- `medium`: Alta precisiÃ³n
- `large`: MÃ¡xima precisiÃ³n, mÃ¡s lento

### Desactivar reducciÃ³n de ruido

En `src/02_normalize_audio.py`, lÃ­nea ~273:
```python
apply_noise_reduction=False  # Cambiar a False
```

## ğŸ“ˆ Rendimiento

Tiempos aproximados por audio de 20 minutos (CPU):

| Script | Tiempo |
|--------|--------|
| 01 - ExtracciÃ³n | ~2 min |
| 02 - NormalizaciÃ³n | ~50s |
| 03 - DiarizaciÃ³n | ~20 min |
| 04 - TranscripciÃ³n | ~30s |
| 05 - GÃ©nero | ~2 min |
| 06 - Reportes | 1s |
| **Total** | **~25 min** |

## ğŸ“ MÃ©todos de ClasificaciÃ³n de GÃ©nero

El sistema usa un **enfoque hÃ­brido**:

1. **AnÃ¡lisis de Pitch (F0)**
   - RÃ¡pido, baseline
   - Male: < 165 Hz
   - Female: â‰¥ 165 Hz

2. **Modelo Pre-entrenado (Wav2Vec2)**
   - Mayor precisiÃ³n (~95%+)
   - DecisiÃ³n final

**LÃ³gica de decisiÃ³n:**
- Si ambos coinciden â†’ Alta confianza
- Si difieren â†’ Usar modelo (mÃ¡s preciso)

## ğŸ› SoluciÃ³n de Problemas

### Error: "HF_TOKEN not found"
- Verifica que el archivo `.env` existe en la raÃ­z
- Verifica que contiene `HF_TOKEN=tu_token`

### Error: "No module named 'pyannote'"
```bash
pip install -r requirements.txt
```

### Error: "GPU not available"
- El pipeline funciona en CPU por defecto
- No es necesario GPU

## ğŸ“ Licencia

Este proyecto es para uso acadÃ©mico/investigaciÃ³n.

## ğŸ‘¥ Contribuciones

Para reportar bugs o sugerir mejoras, contacta al equipo de desarrollo.

## ğŸ“– CÃ³mo Citar Este Proyecto

Si utilizas este software en tu investigaciÃ³n o publicaciÃ³n acadÃ©mica, por favor cÃ­talo de la siguiente manera:

### Formato APA (7Âª ediciÃ³n)
```
[Autor/es]. (2026). Gender Disparity Analysis Pipeline (VersiÃ³n 1.0) [Software]. 
GitHub. https://github.com/ramsestein/gender_disparity_analysis
```

### Formato BibTeX
```bibtex
@software{gender_disparity_pipeline_2026,
  author = {RamsÃ©s Marrero Garcia},
  title = {Gender Disparity Analysis Pipeline: Automated Gender Disparity Analysis in Academic Conferences},
  year = {2026},
  publisher = {GitHub},
  url = {https://github.com/[usuario]/gender_disparity_analysis},
  version = {1.0}
}
```

## ğŸ“š Referencias BibliogrÃ¡ficas

Este proyecto utiliza las siguientes herramientas y bibliotecas de cÃ³digo abierto:

### Herramientas Principales

**Pyannote Audio - DiarizaciÃ³n de Speakers**
```
Bredin, H., & Laurent, A. (2021). End-to-end speaker segmentation for overlap-aware 
resegmentation. In Proc. Interspeech 2021 (pp. 3111-3115).
DOI: 10.21437/Interspeech.2021-560
```
```bibtex
@inproceedings{Bredin2021,
  author = {HervÃ© Bredin and Antoine Laurent},
  title = {{End-to-end speaker segmentation for overlap-aware resegmentation}},
  booktitle = {Proc. Interspeech 2021},
  year = {2021},
  pages = {3111--3115},
  doi = {10.21437/Interspeech.2021-560}
}
```

**OpenAI Whisper - TranscripciÃ³n AutomÃ¡tica**
```
Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., & Sutskever, I. (2022). 
Robust speech recognition via large-scale weak supervision. arXiv preprint arXiv:2212.04356.
```
```bibtex
@article{radford2022whisper,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2212.04356},
  year={2022}
}
```

**Mozilla Common Voice - ClasificaciÃ³n de GÃ©nero**
```
Ardila, R., Branson, M., Davis, K., Henretty, M., Kohler, M., Meyer, J., ... & Weber, G. (2020). 
Common Voice: A massively-multilingual speech corpus. In Proceedings of the 12th Language 
Resources and Evaluation Conference (pp. 4218-4222).
```
```bibtex
@inproceedings{ardila2020common,
  title={Common Voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  booktitle={Proceedings of the 12th Language Resources and Evaluation Conference},
  pages={4218--4222},
  year={2020}
}
```

**Modelo Pre-entrenado:** `alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech`
```
Modelo basado en Wav2Vec2-XLSR-53 fine-tuneado para clasificaciÃ³n de gÃ©nero.
Disponible en: https://huggingface.co/alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech
```

### Bibliotecas de Procesamiento de Audio

**librosa - AnÃ¡lisis de Audio**
```
McFee, B., Raffel, C., Liang, D., Ellis, D. P., McVicar, M., Battenberg, E., & Nieto, O. (2015). 
librosa: Audio and music signal analysis in python. In Proceedings of the 14th Python in Science 
Conference (Vol. 8, pp. 18-25).
```
```bibtex
@inproceedings{mcfee2015librosa,
  title={librosa: Audio and music signal analysis in python},
  author={McFee, Brian and Raffel, Colin and Liang, Dawen and Ellis, Daniel PW and McVicar, Matt and Battenberg, Eric and Nieto, Oriol},
  booktitle={Proceedings of the 14th python in science conference},
  volume={8},
  pages={18--25},
  year={2015}
}
```

